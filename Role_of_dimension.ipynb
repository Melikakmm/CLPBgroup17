{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Role_of_dimension.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOA319mTSNRvg6OecrVQyu2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melikakmm/CLPBgroup17/blob/main/Role_of_dimension.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyRIjlt8c996"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib.ticker import NullFormatter\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# manifold.TSNE\n",
        "from sklearn import manifold  #, datasets\n",
        "from time import time\n",
        "from sklearn.cluster import DBSCAN\n",
        "from collections import OrderedDict\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from   tqdm       import tqdm\n",
        "from pylab import cm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import seaborn    as sns\n",
        "import pandas     as pd\n",
        "from numpy import cos, sin, pi, random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import OrderedDict\n",
        "plt.rcParams['font.size'] = 14\n",
        "mycmap = ListedColormap([\"blue\",\"red\",\"gold\" ])\n",
        "cpalette = [\"blue\",\"red\",\"gold\",\"black\",\"magenta\",\"green\",\"cyan\",\"#1CE6FF\", \"#FF34FF\", \"#FF4A46\",\"#008941\", \"#006FA6\", \"#A30059\", \"#0000A6\", \"#63FFAC\",\"#B79762\", \"#004D43\", \"#8FB0FF\", \"#997D87\",\"#5A0007\", \"#809693\",\"#1B4400\", \"#4FC601\", \"#3B5DFF\", \"#4A3B53\",\"#886F4C\",\"#34362D\", \"#B4A8BD\", \"#00A6AA\", \"#452C2C\",\"#636375\", \"#A3C8C9\", \"#FF913F\", \"#938A81\",\"#575329\", \"#00FECF\", \"#B05B6F\"]\n",
        "\n",
        "\n",
        "!mkdir DATA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ms = 6\n",
        "\n",
        "def clustering(y):\n",
        "    # Finds position of labels and returns a dictionary of cluster labels to data indices.\n",
        "    yu = np.sort(np.unique(y))\n",
        "    clustering = OrderedDict()\n",
        "    for ye in yu:\n",
        "        clustering[ye] = np.where(y == ye)[0]\n",
        "    return clustering\n",
        "\n",
        "def entropy(c, n_sample):\n",
        "    # Measures the entropy of a cluster\n",
        "    h = 0.\n",
        "    for kc in c.keys():\n",
        "        p=len(c[kc])/n_sample\n",
        "        h+=p*np.log(p)\n",
        "    h*=-1.\n",
        "    return h\n",
        "\n",
        "# Normalized mutual information function\n",
        "# Note that this deals with the label permutation problem\n",
        "def NMI(y_true, y_pred):\n",
        "    \"\"\" Computes normalized mutual information: where y_true and y_pred are both clustering assignments\n",
        "    \"\"\"\n",
        "    w = clustering(y_true)\n",
        "    c = clustering(y_pred)\n",
        "    n_sample = len(y_true)\n",
        "\n",
        "    Iwc = 0.\n",
        "    for kw in w.keys():\n",
        "        for kc in c.keys():\n",
        "            w_intersect_c=len(set(w[kw]).intersection(set(c[kc])))\n",
        "            if w_intersect_c > 0:\n",
        "                Iwc += w_intersect_c*np.log(n_sample*w_intersect_c/(len(w[kw])*len(c[kc])))\n",
        "    Iwc/=n_sample\n",
        "    Hc = entropy(c,n_sample)\n",
        "    Hw = entropy(w,n_sample)\n",
        "\n",
        "    return 2*Iwc/(Hc+Hw)\n",
        "\n",
        "def plotting_ax(X, y, ax):\n",
        "    # plotting function\n",
        "    for i, yu in enumerate(np.unique(y)):\n",
        "        pos = (y == yu)\n",
        "        ax.scatter(X[pos,0], X[pos,1],c=cpalette[i%len(cpalette)],s=ms)\n",
        "        if yu == -1:\n",
        "          ax.scatter(X[pos,0], X[pos,1], c='k', s = 10, marker = \"x\")\n",
        "        else\n",
        "          ax.scatter(X[pos,0], X[pos,1], \n",
        "                     c=cpalette[i%len(cpalette)], s= 10, marker = \"o\")\n",
        "    ax.xaxis.set_major_formatter(NullFormatter())\n",
        "    ax.yaxis.set_major_formatter(NullFormatter())\n"
      ],
      "metadata": {
        "id": "VgNeFf0CxDYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Part. In each sample increase the number of dimensions from 3 to L>3, by introducing L-3\n",
        "additional dimensions with noisy inputs. Study how visualization with t-SNE and clustering\n",
        "with DBSCAN are affected by this increase in dimensionality."
      ],
      "metadata": {
        "id": "fjiwz1wVgk8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Who aim to increase the dimension of the data incur in various phenomena know under the name of \"Curse of Dimesionality\", when dimensionality increases, the volume of the space increases so fast that the available data become sparse. In order to obtain a reliable result, the amount of data needed often grows exponentially with the dimensionality. Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties; in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient."
      ],
      "metadata": {
        "id": "j_N7SZzyYoC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define function which take in input the original data and an integer L and\n",
        "#returns x values with noise in the extra dimensions (L)\n",
        "def dimensional_increase(x, L, noise)\n",
        "    x_new = np.random.normal(loc = 0, size = (x.shape[0], (x.shape[1]+L), scale = noise)\n",
        "    x_new[:,0:x.shape[1]] = x\n",
        "    return x_new\n",
        "\n",
        "#load old data\n",
        "fname,fnamey=\"x_3d.dat\",\"y_3d.dat\"\n",
        "data=np.loadtxt(\"DATA/\"+fname, delimiter='\\t')\n",
        "y=np.loadtxt(\"DATA/\"+fnamey,dtype=int)\n",
        "N=len(data)  # number of data samples\n",
        "D=len(data[0])\n",
        "print(\"N=\",N,\"  D=\",D)\n",
        "\n",
        "# increase dimension\n",
        "np.random.seed(12345)\n",
        "L_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "last=L_list[-1]\n",
        "eps_range = [100, 150, 200, 230, 260] #minimum distance between points increase in higher dimensions\n",
        "min_sample_range = [3,5,10,20,24,28,31,34,37] \n",
        "n_component=2\n",
        "perplexity=20\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i, (d, e, m) in enumerate(zip(L_list, eps_range, nim_samples_range)):\n",
        "\n",
        "  new_data = dimensional_increase(data, L_list)\n",
        "  ax = plt.figure(figsize=(4*last, 3*4)).add_subplot(3, last, i+1)\n",
        "\n",
        "  tsne = manifold.TSNE(n_components=n_component, init='random',\n",
        "                         random_state=0, perplexity=perplexity)\n",
        "  Y = tsne.fit_transform(new_data)\n",
        "  \n",
        "  ax.set_title(f\" dimension = {d+3}\")\n",
        "        ax.scatter(Y[:, 0], Y[:, 1], s = 10, c=y,cmap=mycmap, marker = 'o')\n",
        "        ax.tick_params(left=False,bottom=False)\n",
        "        ax.xaxis.set_major_formatter(NullFormatter())\n",
        "        ax.yaxis.set_major_formatter(NullFormatter())\n",
        "\n",
        "  ax = plt.figure(figsize=(4*10, 3*4)).add_subplot(3,last, last + i+1)\n",
        "\n",
        "  model = DBSCAN(eps=e, min_samples=m)\n",
        "  model.fit(new_data)\n",
        "  y_hat = model.labels_\n",
        "  nmi=NMI(y_hat, y)\n",
        "  plotting_ax(Y,y_hat,ax)\n",
        "  ax.set_title(f\"nmi = {nmi}\")\n",
        "  \n",
        "  tsne = manifold.TSNE(n_components = 3, init='random',\n",
        "                         random_state=0, perplexity= 20)\n",
        "  Y = tsne.fit_transform(data_increase)\n",
        "  \n",
        "  ax.set_title(f\" dimension = {d+3}\")\n",
        "  ax.scatter(Y[:,0], Y[:,1],Y[:,2], \n",
        "                   s=10, c=y, depthshade=True, cmap=mycmap, marker = 'o')\n",
        "  ax.xaxis.set_major_formatter(NullFormatter())\n",
        "  ax.yaxis.set_major_formatter(NullFormatter())\n",
        "  ax.zaxis.set_major_formatter(NullFormatter())\n",
        "\n",
        "  ax = plt.figure(figsize=(4*10, 3*4)).add_subplot(3, last, 2*last +i +1, projection = '3d')\n",
        "  \n",
        "plt.show()\n",
        "        \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mqSxpTvLeVRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second Part. To mix the information between all L dimensions while preserving the distances between\n",
        "points, one can also perform some rotation of data with orthonormal random matrices M in\n",
        "O(L): x â†’ M.x"
      ],
      "metadata": {
        "id": "TwuDvB3Tzb0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#new function for dimensional increase and rotation feature\n",
        "def dim_increase_rotate(x, L, noise)\n",
        "    x_new = np.random.normal(loc = 0, size = (x.shape[0], (x.shape[1]+L), scale = noise)\n",
        "    x_new[:,0:x.shape[1]] = x\n",
        "    x_new = x_new.special_ortho_group.rvs(x.shape[1] + L)\n",
        "    return x_new\n",
        "\n",
        "# increase dimension\n",
        "np.random.seed(12345)\n",
        "L_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "last=L_list[-1]\n",
        "eps_range = [100, 150, 200, 230, 260]\n",
        "min_sample_range = [3,5,10,20,24,28,31,34,37]\n",
        "n_component=2\n",
        "perplexity=20\n",
        "\n",
        "\n",
        "\n",
        "for i, (d, e, m) in enumerate(zip(L_list, eps_range, nim_samples_range)):\n",
        "\n",
        "  new_data = dimensional_increase(data, L_list)\n",
        "  ax = plt.figure(figsize=(4*last, 3*4)).add_subplot(3, last, i+1)\n",
        "\n",
        "  tsne = manifold.TSNE(n_components=n_component, init='random',\n",
        "                         random_state=0, perplexity=perplexity)\n",
        "  Y = tsne.fit_transform(new_data)\n",
        "  \n",
        "  ax.set_title(f\" dimension = {d+3}\")\n",
        "        ax.scatter(Y[:, 0], Y[:, 1], s = 10, c=y,cmap=mycmap, marker = 'o')\n",
        "        ax.tick_params(left=False,bottom=False)\n",
        "        ax.xaxis.set_major_formatter(NullFormatter())\n",
        "        ax.yaxis.set_major_formatter(NullFormatter())\n",
        "\n",
        "  ax = plt.figure(figsize=(4*10, 3*4)).add_subplot(3,last, last + i+1)\n",
        "\n",
        "  model = DBSCAN(eps=e, min_samples=m)\n",
        "  model.fit(new_data)\n",
        "  y_hat = model.labels_\n",
        "  nmi=NMI(y_hat, y)\n",
        "  plotting_ax(Y,y_hat,ax)\n",
        "  ax.set_title(f\"nmi = {nmi}\")\n",
        "  \n",
        "  tsne = manifold.TSNE(n_components = 3, init='random',\n",
        "                         random_state=0, perplexity= 20)\n",
        "  Y = tsne.fit_transform(data_increase)\n",
        "  \n",
        "  ax.set_title(f\" dimension = {d+3}\")\n",
        "  ax.scatter(Y[:,0], Y[:,1],Y[:,2], \n",
        "                   s=10, c=y, depthshade=True, cmap=mycmap, marker = 'o')\n",
        "  ax.xaxis.set_major_formatter(NullFormatter())\n",
        "  ax.yaxis.set_major_formatter(NullFormatter())\n",
        "  ax.zaxis.set_major_formatter(NullFormatter())\n",
        "\n",
        "  ax = plt.figure(figsize=(4*10, 3*4)).add_subplot(3, last, 2*last +i +1, projection = '3d')\n",
        "  \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gLOdhjPrzaUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some explanations, dimension increase puts a strain on the ability of tSNE-visualization to clearly separate different data types. Rotating the data let the tSNE initially perform better in lower increased dimensions but it does not change the whole performance along the entire experimentation.\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "YLiwskS5VOex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NjVoNx89izuy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}