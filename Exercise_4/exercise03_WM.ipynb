{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f373046",
      "metadata": {
        "id": "6f373046"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten #, Reshape\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# AdaBoost Algorithm\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "# Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance, to_graphviz, plot_tree\n",
        "\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_importance, plot_tree\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32464298",
      "metadata": {
        "id": "32464298"
      },
      "outputs": [],
      "source": [
        "!pip install tsfresh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries:\n",
        "\n",
        "%run plot.py"
      ],
      "metadata": {
        "id": "CNG8yKa0PXO4"
      },
      "id": "CNG8yKa0PXO4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed for reproducibility\n",
        "np.random.seed(12345)\n",
        "\n",
        "# pattern parameters: Z=nr of steps, A=amplitude\n",
        "Z=12\n",
        "A=500\n",
        "\n",
        "bias = 5\n",
        "\n",
        "# size of each sample of the timeseries\n",
        "L=60\n",
        "# step parameters: introduce small positive bias \n",
        "DX = 50\n",
        "bias = 5\n",
        "n = [20, 50, 100, 150, 200, 250, 300, 400, 500]"
      ],
      "metadata": {
        "id": "qyqZ06S3fZpa"
      },
      "id": "qyqZ06S3fZpa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str0 = 'ts_L60_Z12_A500_DX50_bias5_N10000.dat'\n",
        "fnamex='DATA/x_'+str0\n",
        "fnamey='DATA/y_'+str0\n",
        "\n",
        "x = np.loadtxt(fnamex, delimiter=\" \",dtype=float)\n",
        "N,L = len(x), len(x[0])\n",
        "\n",
        "Show_data(x,L,\"original data\")\n",
        "\n",
        "# note: here it does not need to be converted to the 3-bit version, a label remains y[i]=0,1,2\n",
        "y = np.loadtxt(fnamey, dtype=int)\n",
        "n_class = 3    #  = len(np.unique(y))\n",
        "print('data: ',N)"
      ],
      "metadata": {
        "id": "hZfXqa6hPYFC"
      },
      "id": "hZfXqa6hPYFC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adversarial CNN"
      ],
      "metadata": {
        "id": "5E7fNiC_WVna"
      },
      "id": "5E7fNiC_WVna"
    },
    {
      "cell_type": "code",
      "source": [
        "reg = regularizers.l2(1)\n",
        "ini = keras.initializers.RandomNormal(mean=0.0, stddev=0.5, seed=12345)\n",
        "NF = 10 #number of filters\n",
        "nepoch = 400\n",
        "batch_size = 200\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "def create_model(optimizer = opt, dropout = 0.2,\n",
        "                 activation_hidden_layers = 'relu'):\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(filters=NF, kernel_size=11, \n",
        "                     kernel_initializer=ini, \n",
        "                     kernel_regularizer=reg,\n",
        "                     activation='relu', \n",
        "                     input_shape=input_shape))\n",
        "        model.add(AveragePooling1D(5))\n",
        "        model.add(Conv1D(filters=5, kernel_size=7, activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(12, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "return model\n",
        "#save initial weights\n",
        "initial_weights = model.get_weights()\n",
        "#create model\n",
        "adversarial_model = create model(optimizer = opt, dropout = 0.2,\n",
        "                                activation_hidden_layers = 'relu')"
      ],
      "metadata": {
        "id": "bmyD7HHcS1ZE"
      },
      "id": "bmyD7HHcS1ZE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN performances"
      ],
      "metadata": {
        "id": "X481hwsjd2oB"
      },
      "id": "X481hwsjd2oB"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_df(x)\n",
        "    '''Build input dataframe for given data series\n",
        "    Input:\n",
        "    var = array of time series, (#samples,time,1)\n",
        "    Return:\n",
        "    df = dataframe ready for features extraction\n",
        "    '''\n",
        "    \n",
        "    #N = #samples, t = timesteps\n",
        "    N, t = x.shape[0], x.shape[1]\n",
        "    #build id columns\n",
        "    id_col = np.repeat(np.arange(N),t)\n",
        "    #build time columns\n",
        "    time_col = np.tile(np.arange(t),N)\n",
        "    #build var columns\n",
        "    x_col = x.flatten()\n",
        "      \n",
        "    #build dict for df\n",
        "    x_dict = {'id':id_col,'time':time_col,'value':x_col}\n",
        "        \n",
        "    #return dataframe\n",
        "    return pd.DataFrame(x_dict)"
      ],
      "metadata": {
        "id": "vHkBcHQjdzDF"
      },
      "id": "vHkBcHQjdzDF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# performances for different N\n",
        "# create a dictionary which contains \n",
        "# both cnn and xgboost accuracies\n",
        "\n",
        "for N in n\n",
        "    cnn_acc = []\n",
        "    xgb_acc = []\n",
        "    #load data\n",
        "    x = np.loadtxt(\"DATA/x_\"+ ,delimiter=\" \",dtype=float)\n",
        "    y = np.loadtxt(DATA/y_+fname, dtype=int)\n",
        "    \n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "SkcpkrgCfN6r"
      },
      "id": "SkcpkrgCfN6r",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "colab": {
      "name": "exercise03_WM.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}